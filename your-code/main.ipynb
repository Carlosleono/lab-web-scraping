{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from lxml import html\n",
    "from lxml.html import fromstring\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import re\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"github\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"github\")\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = soup.find_all('p', {'class': 'f4 text-normal mb-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wenzhixin']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "tags[0].getText().split('\\n')[2].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = []\n",
    "for i in tags:\n",
    "    nombres.append(i.getText().split('\\n')[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wenzhixin',\n",
       " 'angus-c',\n",
       " 'yujincheng08',\n",
       " 'bokuweb',\n",
       " 'oerdnj',\n",
       " 'hanxiao',\n",
       " 'JeffreySu',\n",
       " 'tanersener',\n",
       " 'dodyg',\n",
       " 'rusty1s',\n",
       " 'mdlayher',\n",
       " 'jimmywarting',\n",
       " 'dapplion',\n",
       " 'samuelcolvin',\n",
       " 'koaning',\n",
       " 'pepibumur',\n",
       " 'jesserockz',\n",
       " 'PuruVJ',\n",
       " 'dtolnay',\n",
       " 'drwpow',\n",
       " 'JohnSundell',\n",
       " 'mrdoob',\n",
       " 'rmosolgo',\n",
       " 'keegancsmith',\n",
       " 'mikecao']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html2 = requests.get(url2)\n",
    "soup2 = BeautifulSoup(html2.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags2 = soup2.find_all('h1', {'class': 'h3 lh-condensed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python-World / python-mini-projects\n"
     ]
    }
   ],
   "source": [
    "print(tags2[0].getText().split('\\n')[-4].strip(), tags2[0].getText().split('\\n')[-2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = []\n",
    "for i in tags2:\n",
    "    repos.append(i.getText().split('\\n')[-4].strip()+ i.getText().split('\\n')[-2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python-World /python-mini-projects',\n",
       " 'huggingface /datasets',\n",
       " 'espnet /espnet',\n",
       " 'bregman-arie /devops-exercises',\n",
       " 'pytest-dev /pytest',\n",
       " 'tiangolo /fastapi',\n",
       " 'bhky /opennsfw2',\n",
       " 'TachibanaYoshino /AnimeGANv2',\n",
       " 'synacktiv /CVE-2021-40539',\n",
       " 'huggingface /transformers',\n",
       " 'netbox-community /netbox',\n",
       " 'public-apis /public-apis',\n",
       " 'WZMIAOMIAO /deep-learning-for-image-processing',\n",
       " 'ansible /ansible',\n",
       " 'swisskyrepo /PayloadsAllTheThings',\n",
       " 'pytorch /fairseq',\n",
       " 'demisto /content',\n",
       " 'PyGithub /PyGithub',\n",
       " 'danielgatis /rembg',\n",
       " 'tensorflow /models',\n",
       " 'mlflow /mlflow',\n",
       " 'open-mmlab /mmdetection',\n",
       " 'blakeblackshear /frigate',\n",
       " 'cupy /cupy',\n",
       " 'jackfrued /Python-100-Days']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html3 = requests.get(url3)\n",
    "soup3 = BeautifulSoup(html3.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url4 ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html4 = requests.get(url4)\n",
    "soup4 = BeautifulSoup(html4.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags4 = soup4.find_all('div', {'class': 'mw-parser-output'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags4[0].find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"extiw\" href=\"https://en.wiktionary.org/wiki/Python\" title=\"wiktionary:Python\">Python</a>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags4[0].find(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for i in tags4[0].find_all('a'):\n",
    "    links.append(i.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "links = links[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkadisimos =[]\n",
    "\n",
    "for i in links:\n",
    "    linkadisimos.append('https://en.wikipedia.org/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org//w/index.php?title=Python&action=edit&section=3',\n",
       " 'https://en.wikipedia.org//wiki/Python_(Efteling)',\n",
       " 'https://en.wikipedia.org//wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " 'https://en.wikipedia.org//wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " 'https://en.wikipedia.org//w/index.php?title=Python&action=edit&section=4',\n",
       " 'https://en.wikipedia.org//wiki/Python_(automobile_maker)',\n",
       " 'https://en.wikipedia.org//wiki/Python_(Ford_prototype)',\n",
       " 'https://en.wikipedia.org//w/index.php?title=Python&action=edit&section=5',\n",
       " 'https://en.wikipedia.org//wiki/Python_(missile)',\n",
       " 'https://en.wikipedia.org//wiki/Python_(nuclear_primary)',\n",
       " 'https://en.wikipedia.org//wiki/Colt_Python',\n",
       " 'https://en.wikipedia.org//w/index.php?title=Python&action=edit&section=6',\n",
       " 'https://en.wikipedia.org//wiki/PYTHON',\n",
       " 'https://en.wikipedia.org//wiki/Python_(film)',\n",
       " 'https://en.wikipedia.org//wiki/Python_(mythology)',\n",
       " 'https://en.wikipedia.org//wiki/Monty_Python',\n",
       " 'https://en.wikipedia.org//wiki/Python_(Monty)_Pictures',\n",
       " 'https://en.wikipedia.org//w/index.php?title=Python&action=edit&section=7',\n",
       " 'https://en.wikipedia.org//wiki/Cython',\n",
       " 'https://en.wikipedia.org//wiki/Pyton',\n",
       " 'https://en.wikipedia.org//wiki/Pithon',\n",
       " 'https://en.wikipedia.org//wiki/File:Disambig_gray.svg',\n",
       " 'https://en.wikipedia.org//wiki/Help:Disambiguation',\n",
       " 'https://en.wikipedia.org/https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkadisimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "html6 = requests.get(url6)\n",
    "soup6 = BeautifulSoup(html6.content,\"html.parser\")\n",
    "# tags6 = soup6.find_all('div', {'class': 'mw-parser-output'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tab(tab):\n",
    "    Top_alb = []\n",
    "    for s in tab.find_all(\"tr\"):\n",
    "        fila = [elemento for elemento in s.find_all(\"td\")]\n",
    "        if len(fila)>1:\n",
    "            spot_dicc = {\"Date\" : fila[0].text,\n",
    "#                         \"Time\": fila[0].text.split(' ')[1],\n",
    "                         \"latitude\": fila[1].text,\n",
    "                         \"longitud\" :fila[3].text,\n",
    "                         \"Region\" : fila[7].text\n",
    "                        }\n",
    "            Top_alb.append(spot_dicc)\n",
    "    return Top_alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "terremotero =  soup6.findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'earthquake2021-11-11\\xa0\\xa0\\xa015:41:14.011min ago1.65\\xa0S\\xa0\\xa0127.30\\xa0E\\xa0\\xa0150 M3.4\\xa0KEPULAUAN OBI, INDONESIA2021-11-11 15:50'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terremotero[14].getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "terres = []\n",
    "lista = range(14,34)\n",
    "for i in lista:\n",
    "    terres.append(terremotero[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_240/3942118075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mshaky\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     spot_dicc = {\"Date\" : re.search(r'\\d{4}\\-\\d{2}\\-\\d{2}',i),\n\u001b[0m\u001b[1;32m      4\u001b[0m                 \u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d{2}\\:\\d{2}\\:\\d{2}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#                 \"latitude\": re.extract(r'\\d{4}\\-\\d{2}\\-\\d{2}', i),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    200\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "shaky=[]\n",
    "for i in terres:\n",
    "    spot_dicc = {\"Date\" : re.search(r'\\d{4}\\-\\d{2}\\-\\d{2}',i),\n",
    "                \"Time\": re.search(r'\\d{2}\\:\\d{2}\\:\\d{2}'),\n",
    "#                 \"latitude\": re.extract(r'\\d{4}\\-\\d{2}\\-\\d{2}', i),\n",
    "#                 \"longitud\" :re.extract(r'\\d{4}\\-\\d{2}\\-\\d{2}', i),\n",
    "#                 \"Region\" : re.extract(r'\\d{4}\\-\\d{2}\\-\\d{2}', i)\n",
    "                }\n",
    "    shaky.append(spot_dicc)\n",
    "shaky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_240/310832903.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolusio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterremotero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_240/2129505612.py\u001b[0m in \u001b[0;36mdata_tab\u001b[0;34m(tab)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#                         \"Time\": fila[0].text.split(' ')[1],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                          \u001b[0;34m\"latitude\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfila\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                          \u001b[0;34m\"longitud\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfila\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                          \u001b[0;34m\"Region\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfila\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         }\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "solusio = data_tab(terremotero[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'\n",
    "url_hack = 'https://hackevents.co/search/anything/anywhere/anytime' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9de2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.gov.uk/search?filters%5Btopic%5D=Government'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04abd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7cdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = soup.find_all(\"a\", {\"class\": \"govuk-link\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84988a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"govuk-link\" href=\"/cookies\">cookies to collect information</a>,\n",
       " <a class=\"govuk-link\" href=\"/cookies\">View cookies</a>,\n",
       " <a class=\"govuk-link\" data-module=\"gem-track-click\" data-track-action=\"Cookie banner settings clicked from confirmation\" data-track-category=\"cookieBanner\" href=\"/cookies\">change your cookie settings</a>,\n",
       " <a class=\"govuk-link\" href=\"http://www.smartsurvey.co.uk/s/3SEXD/\">feedback</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?q=\">Remove filters</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2a9872d3-f047-4ca8-9f9a-3e4ab7c92c61/air-passenger-duty-bulletin\">Air Passenger Duty Bulletin</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/23f3752c-64ff-4b46-8ba3-46bcb6b02095/estates-data\">Estates Data</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/29065bfe-ade1-415f-96e3-6a8a49b1051b/measuring-tax-gaps\">Measuring Tax Gaps</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/24201e9f-8708-4c9e-abab-f0b8eabc0a4e/crown-prosecution-service-sickness-absence-data\">Crown Prosecution Service Sickness Absence Data</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/26662fdb-c230-4310-b16f-33a8ff472560/revenue-based-taxes-and-benefits-non-domestic-rating-in-england-and-wales\">Revenue-based Taxes and Benefits: Non domestic rating in England and Wales</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2a71ec41-c62b-4d1e-9eec-c108084ebf5f/national-archives-staff-diversity\">National Archives - Staff Diversity</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2f40a2ff-8c76-4ab7-859e-0931c4db07d6/organogram-and-senior-staff-pay-data-for-ofgem\">Organogram and Senior Staff pay data for Ofgem</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2e6d4195-b028-4465-94b2-59b99b7433f9/tax-credits\">Tax Credits</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/30abcffd-ee74-4ca8-98d2-b09796cf292e/alcohol-duties-factsheet\">Alcohol Duties Factsheet</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/35604208-cf9c-4c31-86cb-7098cdd30d4e/crown-prosecution-service-workforce-diversity-data-2011-12\">Crown Prosecution Service workforce diversity data 2011-12</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/36a9bb03-3e93-4c85-84d6-eb2c930dc37e/data-losses\">Data Losses</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/372ba9ea-2c38-46bb-9962-ef144ebde95b/customs-2013-eu-initiative-data\">Customs 2013 EU initiative data</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3c8447a2-d515-46ad-899a-7e24ff436990/national-savings-investments-workforce-management-information\">National Savings &amp; Investments workforce management information</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3581317f-9826-414b-b7bf-c9745efdcf1c/revenue-based-taxes-and-benefits-charitable-donations-and-tax-relief\">Revenue-based Taxes and Benefits: Charitable donations and tax relief</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/37155d4a-414a-484d-b6b6-b3a13de3fa0a/the-national-archives-salaries-for-senior-civil-servants\">The National Archives - Salaries for Senior Civil Servants</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3bf7663c-bae1-4249-a17a-be21d23234f7/crown-prosecution-service-workforce-management-information\">Crown Prosecution Service Workforce Management Information</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3e06a402-8141-4838-b994-38f3ef5dde71/fsa-non-current-asset-register\">FSA Non-Current Asset Register</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3df565d2-7ad1-4afe-98c6-f8f2757245d2/national-archives-legislation-gov-uk-customer-satisfaction\">National Archives - Legislation.gov.uk customer satisfaction</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/9d273878-0e5f-4e12-b84b-79f4ad4b14a6/value-added-tax-vat\">Value Added Tax (VAT)</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/a59bd30a-5731-412b-a0dc-de4844ebacfd/tax-compliance-checks\">Tax Compliance Checks</a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6101eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tag in tags:\n",
    "    a = tag.getText()\n",
    "    list1.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741713a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cookies to collect information',\n",
       " 'View cookies',\n",
       " 'change your cookie settings',\n",
       " 'feedback',\n",
       " 'Remove filters',\n",
       " 'Air Passenger Duty Bulletin',\n",
       " 'Estates Data',\n",
       " 'Measuring Tax Gaps',\n",
       " 'Crown Prosecution Service Sickness Absence Data',\n",
       " 'Revenue-based Taxes and Benefits: Non domestic rating in England and Wales',\n",
       " 'National Archives - Staff Diversity',\n",
       " 'Organogram and Senior Staff pay data for Ofgem',\n",
       " 'Tax Credits',\n",
       " 'Alcohol Duties Factsheet',\n",
       " 'Crown Prosecution Service workforce diversity data 2011-12',\n",
       " 'Data Losses',\n",
       " 'Customs 2013 EU initiative data',\n",
       " 'National Savings & Investments workforce management information',\n",
       " 'Revenue-based Taxes and Benefits: Charitable donations and tax relief',\n",
       " 'The National Archives - Salaries for Senior Civil Servants',\n",
       " 'Crown Prosecution Service Workforce Management Information',\n",
       " 'FSA Non-Current Asset Register',\n",
       " 'National Archives - Legislation.gov.uk customer satisfaction',\n",
       " 'Value Added Tax (VAT)',\n",
       " 'Tax Compliance Checks']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93267ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = list1[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ab98e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air Passenger Duty Bulletin',\n",
       " 'Estates Data',\n",
       " 'Measuring Tax Gaps',\n",
       " 'Crown Prosecution Service Sickness Absence Data',\n",
       " 'Revenue-based Taxes and Benefits: Non domestic rating in England and Wales',\n",
       " 'National Archives - Staff Diversity',\n",
       " 'Organogram and Senior Staff pay data for Ofgem',\n",
       " 'Tax Credits',\n",
       " 'Alcohol Duties Factsheet',\n",
       " 'Crown Prosecution Service workforce diversity data 2011-12',\n",
       " 'Data Losses',\n",
       " 'Customs 2013 EU initiative data',\n",
       " 'National Savings & Investments workforce management information',\n",
       " 'Revenue-based Taxes and Benefits: Charitable donations and tax relief',\n",
       " 'The National Archives - Salaries for Senior Civil Servants',\n",
       " 'Crown Prosecution Service Workforce Management Information',\n",
       " 'FSA Non-Current Asset Register',\n",
       " 'National Archives - Legislation.gov.uk customer satisfaction',\n",
       " 'Value Added Tax (VAT)',\n",
       " 'Tax Compliance Checks']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9de2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.gov.uk/search?filters%5Btopic%5D=Government'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04abd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7cdae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = soup.find_all(\"a\", {\"class\": \"govuk-link\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84988a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"govuk-link\" href=\"/cookies\">cookies to collect information</a>,\n",
       " <a class=\"govuk-link\" href=\"/cookies\">View cookies</a>,\n",
       " <a class=\"govuk-link\" data-module=\"gem-track-click\" data-track-action=\"Cookie banner settings clicked from confirmation\" data-track-category=\"cookieBanner\" href=\"/cookies\">change your cookie settings</a>,\n",
       " <a class=\"govuk-link\" href=\"http://www.smartsurvey.co.uk/s/3SEXD/\">feedback</a>,\n",
       " <a class=\"govuk-link\" href=\"/search?q=\">Remove filters</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2a9872d3-f047-4ca8-9f9a-3e4ab7c92c61/air-passenger-duty-bulletin\">Air Passenger Duty Bulletin</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/23f3752c-64ff-4b46-8ba3-46bcb6b02095/estates-data\">Estates Data</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/29065bfe-ade1-415f-96e3-6a8a49b1051b/measuring-tax-gaps\">Measuring Tax Gaps</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/24201e9f-8708-4c9e-abab-f0b8eabc0a4e/crown-prosecution-service-sickness-absence-data\">Crown Prosecution Service Sickness Absence Data</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/26662fdb-c230-4310-b16f-33a8ff472560/revenue-based-taxes-and-benefits-non-domestic-rating-in-england-and-wales\">Revenue-based Taxes and Benefits: Non domestic rating in England and Wales</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2a71ec41-c62b-4d1e-9eec-c108084ebf5f/national-archives-staff-diversity\">National Archives - Staff Diversity</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2f40a2ff-8c76-4ab7-859e-0931c4db07d6/organogram-and-senior-staff-pay-data-for-ofgem\">Organogram and Senior Staff pay data for Ofgem</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/2e6d4195-b028-4465-94b2-59b99b7433f9/tax-credits\">Tax Credits</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/30abcffd-ee74-4ca8-98d2-b09796cf292e/alcohol-duties-factsheet\">Alcohol Duties Factsheet</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/35604208-cf9c-4c31-86cb-7098cdd30d4e/crown-prosecution-service-workforce-diversity-data-2011-12\">Crown Prosecution Service workforce diversity data 2011-12</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/36a9bb03-3e93-4c85-84d6-eb2c930dc37e/data-losses\">Data Losses</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/372ba9ea-2c38-46bb-9962-ef144ebde95b/customs-2013-eu-initiative-data\">Customs 2013 EU initiative data</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3c8447a2-d515-46ad-899a-7e24ff436990/national-savings-investments-workforce-management-information\">National Savings &amp; Investments workforce management information</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3581317f-9826-414b-b7bf-c9745efdcf1c/revenue-based-taxes-and-benefits-charitable-donations-and-tax-relief\">Revenue-based Taxes and Benefits: Charitable donations and tax relief</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/37155d4a-414a-484d-b6b6-b3a13de3fa0a/the-national-archives-salaries-for-senior-civil-servants\">The National Archives - Salaries for Senior Civil Servants</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3bf7663c-bae1-4249-a17a-be21d23234f7/crown-prosecution-service-workforce-management-information\">Crown Prosecution Service Workforce Management Information</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3e06a402-8141-4838-b994-38f3ef5dde71/fsa-non-current-asset-register\">FSA Non-Current Asset Register</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/3df565d2-7ad1-4afe-98c6-f8f2757245d2/national-archives-legislation-gov-uk-customer-satisfaction\">National Archives - Legislation.gov.uk customer satisfaction</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/9d273878-0e5f-4e12-b84b-79f4ad4b14a6/value-added-tax-vat\">Value Added Tax (VAT)</a>,\n",
       " <a class=\"govuk-link\" href=\"/dataset/a59bd30a-5731-412b-a0dc-de4844ebacfd/tax-compliance-checks\">Tax Compliance Checks</a>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6101eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for tag in tags:\n",
    "    a = tag.getText()\n",
    "    list1.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741713a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cookies to collect information',\n",
       " 'View cookies',\n",
       " 'change your cookie settings',\n",
       " 'feedback',\n",
       " 'Remove filters',\n",
       " 'Air Passenger Duty Bulletin',\n",
       " 'Estates Data',\n",
       " 'Measuring Tax Gaps',\n",
       " 'Crown Prosecution Service Sickness Absence Data',\n",
       " 'Revenue-based Taxes and Benefits: Non domestic rating in England and Wales',\n",
       " 'National Archives - Staff Diversity',\n",
       " 'Organogram and Senior Staff pay data for Ofgem',\n",
       " 'Tax Credits',\n",
       " 'Alcohol Duties Factsheet',\n",
       " 'Crown Prosecution Service workforce diversity data 2011-12',\n",
       " 'Data Losses',\n",
       " 'Customs 2013 EU initiative data',\n",
       " 'National Savings & Investments workforce management information',\n",
       " 'Revenue-based Taxes and Benefits: Charitable donations and tax relief',\n",
       " 'The National Archives - Salaries for Senior Civil Servants',\n",
       " 'Crown Prosecution Service Workforce Management Information',\n",
       " 'FSA Non-Current Asset Register',\n",
       " 'National Archives - Legislation.gov.uk customer satisfaction',\n",
       " 'Value Added Tax (VAT)',\n",
       " 'Tax Compliance Checks']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93267ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = list1[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ab98e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Air Passenger Duty Bulletin',\n",
       " 'Estates Data',\n",
       " 'Measuring Tax Gaps',\n",
       " 'Crown Prosecution Service Sickness Absence Data',\n",
       " 'Revenue-based Taxes and Benefits: Non domestic rating in England and Wales',\n",
       " 'National Archives - Staff Diversity',\n",
       " 'Organogram and Senior Staff pay data for Ofgem',\n",
       " 'Tax Credits',\n",
       " 'Alcohol Duties Factsheet',\n",
       " 'Crown Prosecution Service workforce diversity data 2011-12',\n",
       " 'Data Losses',\n",
       " 'Customs 2013 EU initiative data',\n",
       " 'National Savings & Investments workforce management information',\n",
       " 'Revenue-based Taxes and Benefits: Charitable donations and tax relief',\n",
       " 'The National Archives - Salaries for Senior Civil Servants',\n",
       " 'Crown Prosecution Service Workforce Management Information',\n",
       " 'FSA Non-Current Asset Register',\n",
       " 'National Archives - Legislation.gov.uk customer satisfaction',\n",
       " 'Value Added Tax (VAT)',\n",
       " 'Tax Compliance Checks']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html as lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "url='https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a handle, page, to handle the contents of the website\n",
    "page = requests.get(url)\n",
    "#Store the contents of the website under doc\n",
    "doc = lh.fromstring(page.content)\n",
    "#Parse data that are stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the length of the first 12 rows\n",
    "[len(T) for T in tr_elements[:12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\"Rank\n",
      "\"\n",
      "2:\"Language\n",
      "\"\n",
      "3:\"Speakers(millions)\n",
      "\"\n",
      "4:\"Percentageof world pop.(March 2019)[8]\n",
      "\"\n",
      "5:\"Language family\n",
      "\"\n",
      "6:\"Branch\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "tr_elements = doc.xpath('//tr')\n",
    "#Create empty list\n",
    "col=[]\n",
    "i=0\n",
    "#For each row, store each first element (header) and an empty list\n",
    "for t in tr_elements[1]:\n",
    "    i+=1\n",
    "    name=t.text_content()\n",
    "    print('%d:\"%s\"'%(i,name))\n",
    "    col.append((name,[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since out first row is the header, data is stored on the second row onwards\n",
    "for j in range(1,len(tr_elements)):\n",
    "    #T is our j'th row\n",
    "    T=tr_elements[j]\n",
    "    \n",
    "    #If row is not of size 10, the //tr data is not from our table \n",
    "    if len(T)!=6:\n",
    "        break\n",
    "    \n",
    "    #i is the index of our column\n",
    "    i=0\n",
    "    \n",
    "    #Iterate through each element of the row\n",
    "    for t in T.iterchildren():\n",
    "        data=t.text_content() \n",
    "        #Check if row is empty\n",
    "        if i>0:\n",
    "        #Convert any numerical value to integers\n",
    "            try:\n",
    "                data=int(data)\n",
    "            except:\n",
    "                pass\n",
    "        #Append the data to the empty list of the i'th column\n",
    "        col[i][1].append(data)\n",
    "        #Increment i for the next column\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92, 92, 92, 92, 92, 92]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(C) for (title,C) in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict={title:column for (title,column) in col}\n",
    "df=pd.DataFrame(Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Rank\\n', 'Percentageof world pop.(March 2019)[8]\\n', 'Language family\\n', 'Branch\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language\\n</th>\n",
       "      <th>Speakers(millions)\\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese\\n</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish\\n</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English\\n</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi (sanskritised Hindustani)[9]\\n</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengali\\n</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese\\n</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian\\n</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese\\n</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Western Punjabi[10]\\n</td>\n",
       "      <td>92.7\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marathi\\n</td>\n",
       "      <td>83.1\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Language\\n Speakers(millions)\\n\n",
       "0                    Mandarin Chinese\\n                  918\n",
       "1                             Spanish\\n                  480\n",
       "2                             English\\n                  379\n",
       "3  Hindi (sanskritised Hindustani)[9]\\n                  341\n",
       "4                             Bengali\\n                  300\n",
       "5                          Portuguese\\n                  221\n",
       "6                             Russian\\n                  154\n",
       "7                            Japanese\\n                  128\n",
       "8                 Western Punjabi[10]\\n               92.7\\n\n",
       "9                             Marathi\\n               83.1\\n"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
